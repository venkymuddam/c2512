from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import json
import logging
import time

# Initialize FastAPI app
app = FastAPI()

# Initialize logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Simulate the RAG and Ollama integration as hardcoded functions
def store_data_in_rag(data):
    # Simulate storing data in RAG (actually it will just return a success message)
    logger.info(f"Storing data in RAG: {data}")
    time.sleep(1)  # Simulate a small delay for data storage
    return json.dumps({"message": "Data successfully stored in RAG!"})

def generate_response_from_rag_and_ollama(query):
    # Simulate generating a response using RAG + Ollama (return hardcoded response)
    logger.info(f"Generating response for query: {query}")
    time.sleep(1)  # Simulate response generation delay
    return json.dumps({"message": "Response generated by Ollama!", "response": "This is the response generated."})

# Define the request body models
class MessageRequest(BaseModel):
    message: str

class QueryRequest(BaseModel):
    query: str

# Endpoint to store user message in RAG
@app.post("/store_message/")
async def store_message(request: MessageRequest):
    try:
        # Hardcoded call to RAG to store data
        response = store_data_in_rag(request.message)
        return json.loads(response)  # Return success message from RAG storage
    except Exception as e:
        logger.error(f"Error storing message: {e}")
        raise HTTPException(status_code=500, detail="Error storing message in RAG")

# Endpoint to handle user query
@app.post("/query_response/")
async def query_response(request: QueryRequest):
    try:
        # Hardcoded call to RAG + Ollama to generate a response
        response = generate_response_from_rag_and_ollama(request.query)
        return json.loads(response)  # Return the generated response from RAG + Ollama
    except Exception as e:
        logger.error(f"Error generating response: {e}")
        raise HTTPException(status_code=500, detail="Error generating response from RAG + Ollama")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
